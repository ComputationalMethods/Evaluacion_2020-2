# -*- coding: utf-8 -*-
"""Pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/restrepo/ComputationalMethods/blob/master/material/Pandas.ipynb

# Pandas
<a href="https://colab.research.google.com/github/restrepo/ComputationalMethods/blob/master/material/Pandas.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

From http://pandas.pydata.org/pandas-docs/stable/

pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.

See also:

* https://github.com/restrepo/data-analysis
  * https://classroom.github.com/g/sSMBdBqN
  * https://classroom.github.com/a/PcbQBE7F
* https://github.com/restrepo/PythonTipsAndTricks

A good and practice book about `Pandas` possibilities is:

[__Python for Data Analysis__](https://drive.google.com/open?id=0BxoOXsn2EUNIWExXbVc4SDN0YTQ)<br/>
Data Wrangling with Pandas, NumPy, and IPython<br/>
_By William McKinney_


This other is about aplications based on `Pandas`:
![image.png](https://covers.oreillystatic.com/images/0636920030515/cat.gif) [Introduction to Machine Learning with Python](https://drive.google.com/open?id=0BxoOXsn2EUNISGhrdEZ3S29fS3M)<br/>
A Guide for Data Scientists
By Sarah Guido, Andreas Müller

`Pandas` can be used in a similar way to `R`, which is based on similar data structures. `Pandas` also can replace the use of graphical interfaces to access spreadsheets like Excel

## Standard way to load the module
"""

import pandas as pd

"""## Basic structure: DataFrame

An flat _spreadsheet_ can be seen in terms of the types of variables of `Python` just as dictionary of lists, where each column of the spreadsheet is a pair key-list of the dictionary 

|   |  A   |  B   |
|---|:----:|:----:|
| 1 | even | odd  |
| 2 |   0  | 1    |
| 3 |   2  | 3    |
| 4 |   4  | 5    |
| 5 |   6  | 7    |
| 6 |   8  | 9    |
"""

numbers={"even": [0,2,4,6,8],   #  First  key-list
         "odd" : [1,3,5,7,9] }  #  Second key-list

"""## Data structures

`Pandas` has two new data structures:
1. `DataFrame` which are similar to numpy arrays but with some assigned key. For example, for the previous case
```python
import numpy as np
np.array([[0,1],
          [2,3],
          [4,5],
          [6,7],
          [8,9] 
         ])
```
1. `Series` which are enriched  to dictionaries, as the ones defined for the rows of the previous example: `{'even':0,'odd':1}`.

The rows in a two-dimensional `DataFrame` corresponds to `Series` with similar keys, while the columns are also Series with the indices as keys. 

An example of a  `DataFrame` is a spreadsheet, as the one before.

### `DataFrame`
`Pandas` can convert a dictionary of lists, like the `numbers` dictionary before, into a `DataFrame`, which is just an spreadsheet but interpreted at the programming level:
"""

import pandas as pd
pd.set_option('display.max_colwidth',200)
df=pd.DataFrame(numbers)
df

"""It is equivalent to:"""

pd.DataFrame.from_dict(numbers)

"""See below for other possibilities of [creating Pandas DataFrames from lists and dictionaries](https://fisica.udea.edu.co:4443/user/restrepo/notebooks/prog/cursos/data-analysis/Pandas.ipynb#Intialization-from-lists-and-dictionaries)

The main advantage of the `DataFrame`, `df`, is that it can be managed without a graphical interface.

We can check the shape of the `DataFrame`
"""

df.shape

"""####  Export DataFrame to other formats
* To export to excel:
"""

df.to_excel('example_j.xlsx',index=False)

"""__Activity__: Open the resulting spreadsheet in Google Drive, publish it and open from the resulting link with Pandas in the next cell"""

df=pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vQd2SgnLAmtRveUSvJegGS3tcKo2Fe4bhom4Iij6rMIilaNAtpBWgbO3bD4QPK50g/pub?output=xlsx')
df

"""### `Series`

Each column of the DataFrame is now an augmented dictionary called `Series`, with the indices as the keys of the `Series`

A `Pandas` `Series` object can be just initialized from a `Python` dictionary:
"""

type( df['even'] )

"""The keys are the index of the `DataFrame`"""

df.even[3]

"""Each row is also a series"""

df.loc[0]

"""with keys: `'even'` and `'odd'`"""

df.loc[0]['even']

"""or attributes `even` and `odd`"""

df.loc[0].odd

"""One specific cell value can be reached with the index and the key:"""

df.loc[2,'odd']

s=pd.Series({'Name':'Juan Valdez','Nacionality':'Colombia','Age':23})
s

"""*Note* that the key name can be used also as an attribute."""

df.odd

"""> The __power__ of Pandas rely in that their main data structures: `DataFrames` and `Series`, are enriched with many useful methods and attributes.

### [Official definition of Pandas](http://pandas.pydata.org/pandas-docs/stable/)

> Pandas is a Python package providing __fast__, __flexible__, and __expressive__ _data structures_ designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it _has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool_ available in any language. It is already well on its way toward this goal.

* "relational": the list of data is identified with some unique index (like a `SQL` table)
* "labeled": the list is identified with a key, like the previous `odd` or `even` keys.

For example. A double bracket `[[...]]`, can be used to filter data.

A row in a two-dimensional `DataFrame` corresponds to `Series` with the same keys of the `DataFrame`, but with single values instead of a list
"""

df.loc[[0]]

print( 'the row has' )
print( '                  keys: {} and values: {}'.format( list( df.loc[[0]].keys() ),df.loc[[0]].values[0]  ) )
print( "like the dictionay:" )
print( "                      { 'even' : 0, 'odd' : 1 }")

"""To filter a column:"""

df[['odd']]

"""### More on `Series`

A `Pandas` `Series` object can be just initialized from a `Python` dictionary:
"""

s=pd.Series({'Name':'Juan Valdez','Nacionality':'Colombia','Age':23})
s

s['Name']

"""but also as containers of name spaces!"""

s.Name

"""## `DataFrame` initialization

### Initization from an existing spreadsheet. 
This can be locally in your computer o from some downloadable  link
"""

df=pd.read_excel('http://bit.ly/spreadsheet_xlsx')
df

"""To make a downloadable link for any spread sheet in Google Drive, follow the sequence:
```
File → Publish to the web...→ Entire Document → Web page → Microsoft excel (xlsx)
```
as illustrated in the figure:
![GS](https://github.com/restrepo/data-analysis/blob/master/img/img1.png?raw=1)
"""

df.loc[0,'Edad']=32
df

"""*After* some modification

it can be saved again as an `excel file` with the option to not create a column of indices: `index=False`

### Intialization from lists and dictionaries

#### Inizialization from Series
We start with an empty `DataFrame`:

Creating Pandas DataFrame from list and dictionaries [offers many alternatives](http://pbpython.com/pandas-list-dict.html)

![creating dataframes](http://pbpython.com/images/pandas-dataframe-shadow.png)

#### Row oriented way
* In addition to the dictionary of lists [already illustrated at the beginning]() that in this case corresponds to:
"""

pd.DataFrame({'Nombre'   : ['Juan Valdez','Álvaro Uribe Vélez'],
              'Edad'     : [32,            65                 ],
              'Compañia' : ['Café de Colombia','Senado de la República']})

"""* We can obtain the DataFrame from list of items"""

pd.DataFrame.from_items([ [ 'Nombre'  , ['Juan Valdez','Álvaro Uribe Vélez']],
                          [ 'Edad'    , [  32,            65               ]],
                          [ 'Compañia', ['Café de Colombia','Senado de la República']] ])

"""* We can obtain the `DataFrame` from dictionary"""

pd.DataFrame( {'Nombre':'Juan Valdez',        'Edad': 32   ,'Compañia':'Café de Colombia'      },
              {'Nombre':'Álvaro Uribe Vélez', 'Edad': 65   ,'Compañia':'Senado de la República'}
            )

df=pd.DataFrame()
df

"""### Initialization from sequential rows as  Series
We start with an empty `DataFrame`:
"""

df=pd.DataFrame()
df.empty

"""We can append a dictionary (or Series) as a row of the `DataFrame`, provided that we always use the option: `ignore_index=True`"""

d={'Name':'Juan Valdez','Nacionality':'Colombia','Age':23}
df=df.append(d,ignore_index=True)
df

"""We can fix the type of data of the `'Age'` column"""

type(df.Age)

df['Age']=df.Age.astype(int)
df

"""To add a second file we build another `dict`"""

d={}
for k in ['Name','Nacionality','Age','Company']:
    var=input('{}:\n'.format(k))
    d[k]=var

d

df = df.append(d,ignore_index= True)
df

"""#### Exercises
* Display the resulting `Series` in the screen:
"""

df

"""* Append to the previous `DataFrame` and visualize it:"""



"""* Fill NaN with empty strings"""

df.loc[0]['Company'] = ''
df

"""* Save `Pandas` `DataFrame` as an Excel file"""

df.to_excel('actividad.xlsx', index=False)

"""* Load pandas DataFrame from the saved file in Excel"""

pd.read_excel('actividad.xlsx')

"""### Common operations upon `DataFrames`
See https://github.com/restrepo/PythonTipsAndTricks

* __To fill a specific cell__
"""

df.loc[0,'Company']='Federación de Caferos'

df

"""## Other formats to saving and read files
We are interested in format which keeps the tags of the columns, like `'Nombre', 'Edad', 'Compañia'`
"""

df=pd.read_excel('http://bit.ly/spreadsheet_xlsx')
df

"""#### CSV"""

df.to_csv('hoja.csv',index=False)

df

"""We can check the explicit file format with"""

print(df.to_csv(None,index=False))

"""#### JSON

This format keeps the lists and dictionaries at the storage level
"""

df=pd.DataFrame([{"Name":"Donald Trump","Age":73},{"Name":"Barak Obama", "Age":58}])
df

"""This format allow us to keep exactly the very same list of dictionaries structure!"""

print(df.to_json(None,orient='records'))

"""__Activity__: 
* Save to a file instead of `None` and open the file with some editor.
"""



"""* Add a break-line at the end of the first dictionary and try to
load the resulting file with `pd.read_json`
"""



"""JSON allows for some flexibility in the break-lines structure:"""

pd.read_json('''
             [{"Name":"Donald Trump","Age":73},
              {"Name":"Barak Obama", "Age":58}]
            ''')

"""For large databases it is convinient just to accumulate dictionaries in a sequential form:"""

print(df.to_json(None,orient='records',lines=True))

pd.read_json('''
             {"Name":"Donald Trump","Age":73}
             {"Name":"Barak Obama", "Age":58}
            ''',orient='records',lines=True)

"""__Activity__: 
* Save to a file instead of `None`, with options: `orient='records',lines=True`, and open the file with some editor.
"""



"""* Add a similar dictionary in the next new line, and try to
load the resulting file with `pd.read_json` with options: `orient='records',lines=True`. 
   * WARNING: Use doble-quotes `"` to write the keys od the new
dictionary

Any Python string need to be converted first to double-quotes before to be used as JSON string.

__Example__
"""

numbers={"even": [0,2,4,-6,8],   #  First  key-list
         "odd" : [1,3,-5,7,9] }  #  Second key-list

str(numbers)

"""This string can be writing in the `JSON` format by replacing the single quotes, ' , by  duoble quotes, ":"""

str(numbers).replace("'",'"')

"""and now can be used as an JSON input"""

df=pd.read_json(  str(numbers).replace("'",'"') )

"""__Activity__: Try to read the string as JSON without make the double-quote replacement"""



"""## Filters
The main application of labeled data for data analysis is the possibility to make filers, or cuts, to obtain specific reduced datasets to further analysis
"""

df[df.even.abs()>4]

#and
df[(df.even>0) & (df.odd<0)]

#or
df[(df.even<0) | (df.odd<0)]

"""## The `apply` method
The advantage of the spreadsheet paradigm is that the columns can be transformed with functions. All the typical functions avalaible for a spreadsheet are already implemented like the method `.abs()` used before, or the method: `.sum()`
"""

df.even.sum()

"""__Activity__: Explore the avalaible methods by using the completion system of the notebook after the last semicolon of `df.even.`

In addittion, for the `DataFrame` paradigm, we can easy implement any other function directly at the programming level either along the columns or along the rows

### Column-level `apply`
We just select the column and apply the direct or implicit function:
* Pre-defined function
"""

df.even.apply(abs)

"""* Implicit function"""

df.even.apply(lambda n:isinstance(n,int))

"""### Row-level apply
The foll row is passed as dictionary to the explicit or implicit function when `apply` is used for the full `DataFrame` and the option `axis=1` is used at the end
"""

df.apply(lambda row: row['even']+row['odd'],axis='columns')

"""## Non-relational databases

We have shown that the simple two dimensional spreadsheets where each cell values is a simple type like string, integer, or float, can be represented as a dictionary of lists values or a list of dictionary column-value assignment. 

We can go further and allow to store in the value itself a more general data structure, like nested lists and dictionaries. This allows advanced data-analysis when the `apply` methos is used to operate inside the nested lists or dictionaries.

See for example:

##  Machine web
There are really three kinds of web
* The normal web, 
* The deep web,
* _The machine web_. The web for machine readable responses. It is served in `JSON` or `XML`  formats, which preserve programming objects.

For example, consider the following normal web page:

http://old.inspirehep.net/search?p=doi:10.1103/PhysRevLett.122.132001

about a Scientific paper with people from the University of Antioquia. A _machine web_ version can be easily obtained in JSON just by attaching the extra parameter `&of=recjson`, and direcly loaded from Pandas, which works like a _browser for the third web_:
"""

import pandas as pd

df=pd.read_json('http://old.inspirehep.net/search?p=doi:10.1103/PhysRevLett.122.132001&of=recjson')

df

"""We can see that the column `authors` is quite nested: Is a list of dictionaries with the full information for each one of the authors of the article."""

df.number_of_authors

df.authors

"""__Activity__: Check that the lenght of the auhors list coincides with the `number_of_authors` 
<!-- df.authors.apply(len),df.number_of_authors.values -->
"""

df.authors[0][0]



"""We can use all the previous methods to extract the authors from `'Antioquia U.'`:
 
 Note: For a dictionary, `d` is safer to use `d.get('key')` instead of just `d['key']` to obtain some `key`, because not error is generated if the requested `key` does not exists at all
"""

l=[1,2,3]

[x if x>1 else 3 for x in l ]

df.authors.apply(lambda l:  #implicit function
                           [ d.get('full_name') #safer way to obtain a `key` value
                             for d in l   #comprehension list 
                              if isinstance(d,dict) and d.get('affiliation')=='Antioquia U.' #condition
                           ] 
                             if isinstance(l,list) else None #  Be sure that cell have the proper format
                 )

"""A simpler version is possible,  but is more prompted to error when used through multiple column entries:"""

df.authors.apply(lambda l: [ d['full_name'] for d in l   
                              if d['affiliation']=='Antioquia U.'
                           ] )

"""For further details see: https://github.com/restrepo/inspire/blob/master/gfif.ipynb

__Activity__: Repeat the same activity but using directly the JSON file
"""

#See: https://github.com/inspirehep/rest-api-doc/issues/4#issuecomment-645218074
import requests                                                                                                                                                      
response = requests.get('https://inspirehep.net/api/doi/10.1103/PhysRevLett.122.132001')                                                                              
authors = response.json()['metadata']['authors']                                                                                                                     
names = [author.get('full_name')
              for author in authors 
               if any(aff.get('value') == 'Antioquia U.' for aff in author.get('affiliations'))]
names

"""##  ACTIVITIES
See:
* https://github.com/ajcr/100-pandas-puzzles
* https://github.com/guipsamora/pandas_exercises

## Final remarks
With basic scripting and Pandas we already have a solid environment to analyse data. We introduce the other libraries motivated with the extending the capabilities of Pandas
"""

